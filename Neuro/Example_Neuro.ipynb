{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBekiU2+gsAiHLozuqA2wG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports the necessary libraries for the notebook. It includes PyTorch for building and training neural networks, scikit-learn for data splitting and cross-validation, NumPy for numerical operations, Matplotlib for plotting, and Pandas for data manipulation."
      ],
      "metadata": {
        "id": "YDYoz7Sqs8Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fxWH8AAns0wP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset from a file named dataset.txt into a Pandas DataFrame. The dataset contains features like total_flights, num_cancellations, time_since_booking, and season_cancelled, with a target label cancel_label. The features and labels are converted into PyTorch tensors. The data is then split into training and testing sets using an 80-20 split."
      ],
      "metadata": {
        "id": "fYk8Ooo1-_Pb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v8pevwkbfCqa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"dataset.txt\", header=None, names=['total_flights', 'num_cancellations', 'time_since_booking', 'season_cancelled', 'cancel_label'])\n",
        "\n",
        "X = torch.tensor(df[['total_flights', 'num_cancellations', 'time_since_booking', 'season_cancelled']].values, dtype=torch.float32)\n",
        "y = torch.tensor(df['cancel_label'].values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a neural network model called CancellationPredictor using PyTorch. The model consists of three fully connected layers with ReLU activation functions and a sigmoid activation function for the output layer. The model is initialized with the input size derived from the training data. The Adam optimizer and Binary Cross-Entropy Loss (BCELoss) are set up for training."
      ],
      "metadata": {
        "id": "wFT8rWPf_EFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class CancellationPredictor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(CancellationPredictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "model = CancellationPredictor(input_size)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "E95PlEqWfNnZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to calculate the accuracy"
      ],
      "metadata": {
        "id": "71yJfjmd_VP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "\n",
        "    y_pred_labels = (y_pred > 0.5).float()\n",
        "    correct = (y_pred_labels == y_true).float()\n",
        "    return correct.mean().item()"
      ],
      "metadata": {
        "id": "1irX5uK7f1Tj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform 5-fold cross-validation on the training data. For each fold, the model is trained for 15 epochs, and the validation loss and accuracy are computed. The results for each fold are stored, and the average validation loss and accuracy across all folds are printed."
      ],
      "metadata": {
        "id": "sHKVdpcv_ZqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = {'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(X_train)):\n",
        "    print(f'Fold {fold+1}')\n",
        "    X_train_fold, X_val_fold = X_train[train_ids], X_train[val_ids]\n",
        "    y_train_fold, y_val_fold = y_train[train_ids], y_train[val_ids]\n",
        "\n",
        "    for epoch in range(15):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train_fold)\n",
        "        loss = criterion(outputs, y_train_fold)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val_fold)\n",
        "        val_loss = criterion(val_outputs, y_val_fold)\n",
        "        val_acc = accuracy(y_val_fold, val_outputs)\n",
        "\n",
        "        results['val_loss'].append(val_loss.item())\n",
        "        results['val_accuracy'].append(val_acc)\n",
        "\n",
        "        print(f'Validation Loss: {val_loss.item()}, Validation Accuracy: {val_acc}')\n",
        "\n",
        "print(f'Average Validation Loss: {np.mean(results[\"val_loss\"])}')\n",
        "print(f'Average Validation Accuracy: {np.mean(results[\"val_accuracy\"])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9aitAt5fWqe",
        "outputId": "af5977f7-b0aa-4843-b5a6-030197aab729"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Validation Loss: 0.16771748661994934, Validation Accuracy: 0.96875\n",
            "Fold 2\n",
            "Validation Loss: 0.2800973951816559, Validation Accuracy: 0.934374988079071\n",
            "Fold 3\n",
            "Validation Loss: 0.21172788739204407, Validation Accuracy: 0.9593750238418579\n",
            "Fold 4\n",
            "Validation Loss: 0.29636016488075256, Validation Accuracy: 0.9281250238418579\n",
            "Fold 5\n",
            "Validation Loss: 0.16623060405254364, Validation Accuracy: 0.96875\n",
            "Average Validation Loss: 0.2244267076253891\n",
            "Average Validation Accuracy: 0.9518750071525574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the trained model on the test set. The model is set to evaluation mode, and the test loss and accuracy are computed and printed."
      ],
      "metadata": {
        "id": "dEitz8vH_xsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    test_acc = accuracy(y_test, test_outputs)\n",
        "    print(f'Test Loss: {test_loss.item()}, Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w8F1YVOfbi8",
        "outputId": "6df0bc51-7b42-493d-e719-cb898ec7b920"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2049340456724167, Test Accuracy: 0.9549999833106995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstrate how to use the trained model to make predictions on new data. Three sample data points are provided, and the model predicts the probability of cancellation for each. The probabilities are stored in a list and printed."
      ],
      "metadata": {
        "id": "zrJzfZCzAGI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fly = [[112,9,133,3], [68,5,365,3], [56,3,209,1]]\n",
        "\n",
        "data = np.copy(fly)\n",
        "pr = []\n",
        "\n",
        "for person in data:\n",
        "\n",
        "    person_data = {\n",
        "        'total_flights': person[0],\n",
        "        'num_cancellations': person[1],\n",
        "        'time_since_booking': person[2],\n",
        "        'season_cancelled': person[3]\n",
        "    }\n",
        "\n",
        "\n",
        "    person_tensor = torch.tensor([person_data['total_flights'],\n",
        "                                  person_data['num_cancellations'],\n",
        "                                  person_data['time_since_booking'],\n",
        "                                  person_data['season_cancelled']], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(person_tensor)\n",
        "        probability = prediction.item()\n",
        "\n",
        "    pr.append(probability)\n",
        "\n",
        "print(pr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfxlLIWsfnIX",
        "outputId": "da578a4d-2273-4a7b-a485-d188f03ed962"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06298530101776123, 0.008177933283150196, 0.06501767039299011]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the probability that at least one of the passengers in the sample data will cancel their booking. It uses the predicted probabilities from the previous cell to compute this."
      ],
      "metadata": {
        "id": "6qDtborsAX8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities = np.array(pr)\n",
        "\n",
        "prob_no_one_cancels = np.prod(1 - predicted_probabilities)\n",
        "\n",
        "prob_at_least_one_cancels = 1 - prob_no_one_cancels\n",
        "\n",
        "print(f'Вероятность того, что хотя бы один пассажир откажется: {prob_at_least_one_cancels:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEc5TEKFuXIL",
        "outputId": "8d12c9ae-2fa9-4d0b-cb85-ae9b9a78da86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вероятность того, что хотя бы один пассажир откажется: 0.1311\n"
          ]
        }
      ]
    }
  ]
}